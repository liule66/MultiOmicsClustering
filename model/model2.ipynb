{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 导入必要库\n",
    "import gzip\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines.statistics import logrank_test\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "818f3dd27e345526"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 加载数据集函数\n",
    "def load_csv(file_path, nrows=None):\n",
    "    return pd.read_csv(file_path, sep='\\t', nrows=nrows, engine='python')\n",
    "\n",
    "# 加载数据集\n",
    "gene_expression = load_csv('EB++AdjustPANCAN_IlluminaHiSeq_RNASeqV2.geneExp.xena', nrows=20000)\n",
    "print(\"Size of gene_expression dataset: \", gene_expression.shape)\n",
    "dna_methylation = load_csv('DNA_methylation_450k', nrows=100000)\n",
    "print(\"Size of dna_methylation dataset: \", dna_methylation.shape)\n",
    "mirna_expression = load_csv('pancanMiRs_EBadjOnProtocolPlatformWithoutRepsWithUnCorrectMiRs_08_04_16.xena', nrows=700)\n",
    "print(\"Size of mirna_expression dataset: \", mirna_expression.shape)\n",
    "# 选取 clinical 数据\n",
    "clinical_raw_data = pd.read_csv('Survival_SupplementalTable_S1_20171025_xena_sp', sep='\\t', index_col=0)"
   ],
   "id": "34f273e444c81227"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 获取每个数据集的列名（样本 ID）\n",
    "gene_expression_samples = set(gene_expression.columns)\n",
    "dna_methylation_samples = set(dna_methylation.columns)\n",
    "miRNA_expression_samples = set(mirna_expression.columns)\n",
    "clinical_samples = set(clinical_raw_data.index)\n",
    "\n",
    "# 找到所有数据集中共有的样本 ID\n",
    "common_samples = gene_expression_samples & dna_methylation_samples & miRNA_expression_samples & clinical_samples\n",
    "\n",
    "\n",
    "common_samples = list(common_samples)\n",
    "\n",
    "# 使用共有的样本 ID 来过滤每个数据集\n",
    "gene_expression_data = gene_expression[common_samples]\n",
    "dna_methylation_data = dna_methylation[common_samples]\n",
    "miRNA_expression_data = mirna_expression[common_samples]\n",
    "clinical_data = clinical_raw_data.loc[common_samples]\n",
    "print(\"Size of gene_expression_data: \", gene_expression_data.shape)\n",
    "print(\"Size of dna_methylation_data: \", dna_methylation_data.shape)\n",
    "print(\"Size of miRNA_expression_data: \", miRNA_expression_data.shape)\n",
    "\n",
    "print(\"load dataset Successfully\")"
   ],
   "id": "3df5a5febb6766e2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 定义清理函数\n",
    "\n",
    "def clean_data(data):\n",
    "    # 将非数字强制转换为NaN\n",
    "    data = data.apply(pd.to_numeric, errors='coerce')\n",
    "    # 删除缺失值过多的列\n",
    "    data = data.dropna(axis=1, thresh=0.7*data.shape[0])\n",
    "    # 填充缺失值\n",
    "    data = data.apply(lambda row: row.fillna(row.mean()), axis=1)\n",
    "    # 异常值处理，这里使用简单的方法将所有值限制在其99%的分位数范围内\n",
    "    for column in data.columns:\n",
    "        upper_limit = data[column].quantile(0.99)\n",
    "        lower_limit = data[column].quantile(0.01)\n",
    "        data[column] = data[column].clip(lower=lower_limit, upper=upper_limit)\n",
    "    # 特征缩放\n",
    "    scaler = MinMaxScaler()\n",
    "    data = pd.DataFrame(scaler.fit_transform(data), columns=data.columns)\n",
    "    return data\n",
    "\n",
    "# 清理每种数据\n",
    "gene_expression_data = clean_data(gene_expression_data)\n",
    "dna_methylation_data = clean_data(dna_methylation_data)\n",
    "mirna_expression_data = clean_data(miRNA_expression_data)\n",
    "# 将 clinical 数据中 OS.time 的NaN值替换为 last_contact_days_to 值\n",
    "clinical_data['OS.time'] = clinical_data['OS.time'].fillna(clinical_data['last_contact_days_to'])\n",
    "clinical_data['OS.time'].fillna(clinical_data['OS.time'].mean(), inplace=True)\n",
    "# 数据预处理\n",
    "# 只使用数值列进行标准化\n",
    "gene_expression_data = gene_expression_data.iloc[:, :].values.T\n",
    "dna_methylation_data = dna_methylation_data.iloc[:, :].values.T\n",
    "mirna_expression_data = mirna_expression_data.iloc[:, :].values.T\n",
    "\n",
    "print(\"Size of gene_expression_data: \", gene_expression_data.shape)\n",
    "print(\"Size of dna_methylation_data: \", dna_methylation_data.shape)\n",
    "print(\"Size of miRNA_expression_data: \", mirna_expression_data.shape)"
   ],
   "id": "fdd04ca36fdb2505"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "scaler = StandardScaler()\n",
    "gene_expression_scaled = scaler.fit_transform(gene_expression_data)\n",
    "dna_methylation_scaled = scaler.fit_transform(dna_methylation_data)\n",
    "mirna_expression_scaled = scaler.fit_transform(mirna_expression_data)\n",
    "\n",
    "# PCA降维\n",
    "pca_gene = PCA(n_components=1000)\n",
    "pca_dna = PCA(n_components=10000)\n",
    "pca_mirna = PCA(n_components=100)\n",
    "\n",
    "print(\"PCA step completed\")\n",
    "\n",
    "gene_expression_pca = pca_gene.fit_transform(gene_expression_scaled)\n",
    "dna_methylation_pca = pca_dna.fit_transform(dna_methylation_scaled)\n",
    "mirna_expression_pca = pca_mirna.fit_transform(mirna_expression_scaled)\n",
    "\n",
    "# 数据整合\n",
    "integrated_data = np.concatenate([gene_expression_pca, dna_methylation_pca, mirna_expression_pca], axis=1)\n",
    "print(\"Size of integrated_data: \", integrated_data.shape)\n",
    "\n",
    "# 转换为张量\n",
    "X_integrated = torch.tensor(integrated_data, dtype=torch.float32)\n",
    "y_dummy = torch.tensor(np.random.randint(0, 5, integrated_data.shape[0]), dtype=torch.long)\n",
    "\n",
    "# 创建数据加载器\n",
    "dataset = TensorDataset(X_integrated,y_dummy)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# 检查是否有可用的GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ],
   "id": "86306960b5d9eca5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 定义模型\n",
    "class ImprovedMultiOmicsNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImprovedMultiOmicsNN, self).__init__()\n",
    "        self.fc_gene = nn.Sequential(\n",
    "            nn.Linear(1000, 648),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(648, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc_dna = nn.Sequential(\n",
    "            nn.Linear(10000, 6480),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(6480, 2560),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2560, 1280),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1280, 640),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(640, 320),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(320, 160),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(160, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc_mirna = nn.Sequential(\n",
    "            nn.Linear(100, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc_combined = nn.Sequential(\n",
    "            nn.Linear(32 * 3, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 2100)\n",
    "        )\n",
    "\n",
    "    def forward(self, x_integrated):\n",
    "        x_gene_encoded = self.fc_gene(x_integrated[:, :1000])\n",
    "        x_dna_encoded = self.fc_dna(x_integrated[:, 1000:2000])\n",
    "        x_mirna_encoded = self.fc_mirna(x_integrated[:, 2000:])\n",
    "        x_combined = torch.cat((x_gene_encoded, x_dna_encoded, x_mirna_encoded), dim=1)\n",
    "        output = self.fc_combined(x_combined)\n",
    "        return output\n",
    "\n",
    "# 使用改进的模型\n",
    "model = ImprovedMultiOmicsNN().to(device)\n",
    "\n",
    "# 调整学习率和优化器\n",
    "\n",
    "# 定义优化器和损失函数\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "# 定义重构损失函数\n",
    "def reconstruction_loss(reconstructed, original):\n",
    "    mse_loss = nn.MSELoss()\n",
    "    return mse_loss(reconstructed, original)\n",
    "\n",
    "# 训练模型\n",
    "num_epochs = 50\n",
    "prev_loss = float('inf')\n",
    "loss_list = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    for X,_ in dataloader:\n",
    "\n",
    "        X = X.to(device)\n",
    "\n",
    "        # 前向传播\n",
    "        outputs= model(X)\n",
    "        loss = reconstruction_loss(outputs, X)\n",
    "\n",
    "        # 反向传播和优化\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    epoch_loss /= len(dataloader)\n",
    "    loss_list.append(epoch_loss)\n",
    "\n",
    "\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss:.4f}')"
   ],
   "id": "372c454cd6e4e115"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 在整个数据集上重新计算模型的输出\n",
    "all_outputs = []\n",
    "model.eval()  # 切换到评估模式\n",
    "with torch.no_grad():\n",
    "    for X, _ in dataloader:\n",
    "        X = X.to(device)\n",
    "        output_batch = model(X)\n",
    "        all_outputs.append(output_batch.cpu().numpy())\n",
    "\n",
    "# 合并所有批次的输出\n",
    "all_outputs = np.concatenate(all_outputs, axis=0)\n",
    "print(\"Size of all_outputs: \", all_outputs.shape)\n",
    "\n",
    "# 使用聚类算法进行聚类分析\n",
    "kmeans = KMeans(n_clusters=4, random_state=42)\n",
    "labels = kmeans.fit_predict(all_outputs)\n",
    "\n",
    "# 结果评估（轮廓系数）\n",
    "silhouette_avg = silhouette_score(all_outputs, labels)\n",
    "print(f'Silhouette Score: {silhouette_avg}')\n",
    "\n",
    "# 使用PCA降维\n",
    "pca = PCA(n_components=2)\n",
    "outputs_2d = pca.fit_transform(all_outputs)\n",
    "\n",
    "# 绘制散点图\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(outputs_2d[:, 0], outputs_2d[:, 1], c=labels)\n",
    "plt.title('Cluster Visualization')\n",
    "plt.savefig('cluster_visualization.png')  # 保存图像而不是显示\n",
    "plt.close()\n",
    "\n",
    "# 绘制训练的损失曲线\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(loss_list, label='Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig('training_loss.png')  # 保存图像而不是显示\n",
    "plt.close()"
   ],
   "id": "3bd49c693859ae57"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def find_optimal_k_and_plot(survival_data, combined_data, k_range):\n",
    "    optimal_k = None\n",
    "    best_p_value = 1  # 初始化为最大的p值\n",
    "    best_labels = None\n",
    "    total_p_values = []\n",
    "\n",
    "    for k in k_range:\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "        labels = kmeans.fit_predict(all_outputs)\n",
    "\n",
    "        survival_data['Cluster'] = labels\n",
    "        kmf = KaplanMeierFitter()\n",
    "        survival_curves = []\n",
    "\n",
    "        for cluster in np.unique(labels):\n",
    "            cluster_data = survival_data[survival_data['Cluster'] == cluster]\n",
    "            T = cluster_data['OS.time']\n",
    "            E = np.where(cluster_data['vital_status'] == 'Alive', 1, 0)\n",
    "            kmf.fit(T, event_observed=E)\n",
    "            survival_curves.append((T, E))\n",
    "\n",
    "        # 计算不同聚类之间的生存曲线差异\n",
    "        p_values = []\n",
    "        for i in range(len(survival_curves) - 1):\n",
    "            for j in range(i + 1, len(survival_curves)):\n",
    "                result = logrank_test(survival_curves[i][0], survival_curves[j][0],\n",
    "                                      event_observed_A=survival_curves[i][1], event_observed_B=survival_curves[j][1])\n",
    "                p_values.append(result.p_value)\n",
    "\n",
    "        # 选择差异最大（p值最小）的聚类结果\n",
    "        min_p_value = np.mean(p_values) if p_values else 1\n",
    "        total_p_values.append(min_p_value)\n",
    "        if min_p_value < best_p_value:\n",
    "            best_p_value = min_p_value\n",
    "            optimal_k = k\n",
    "            best_labels = labels\n",
    "\n",
    "    # 可视化不同簇数量下的p值\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(k_range, total_p_values, 'bx-')\n",
    "    plt.xlabel('Number of clusters (k)')\n",
    "    plt.ylabel('P values')\n",
    "    plt.title('P values for Different k')\n",
    "    plt.savefig('p_values.png')  # 保存图像而不是显示\n",
    "    plt.close()\n",
    "\n",
    "    # 使用最优的k值进行聚类，并画出生存曲线图\n",
    "    if optimal_k:\n",
    "        print(f\"Optimal k: {optimal_k} with p-value: {best_p_value}\")\n",
    "        survival_data['Cluster'] = best_labels\n",
    "        kmf = KaplanMeierFitter()\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        for cluster in np.unique(best_labels):\n",
    "            cluster_data = survival_data[survival_data['Cluster'] == cluster]\n",
    "            T = cluster_data['OS.time']\n",
    "            E = np.where(cluster_data['vital_status'] == 'Alive', 1, 0)\n",
    "            kmf.fit(T, event_observed=E, label=f'Cluster {cluster}')\n",
    "            kmf.plot_survival_function()\n",
    "\n",
    "        plt.title('Survival Analysis by Cluster with Optimal k')\n",
    "        plt.savefig('survival_analysis.png')  # 保存图像而不是显示\n",
    "        plt.close()\n",
    "    else:\n",
    "        print(\"No optimal k found.\")\n",
    "\n",
    "find_optimal_k_and_plot(clinical_data, all_outputs, range(2, 10))"
   ],
   "id": "9fefe6f8e1734904"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
