{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# 导入必要库\n",
    "import gzip\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from lifelines import KaplanMeierFitter\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T03:28:37.801845Z",
     "start_time": "2024-07-11T03:28:37.796567Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 加载数据集函数\n",
    "def load_csv(file_path, nrows=None):\n",
    "    return pd.read_csv(file_path, sep='\\t', nrows=nrows, engine='python')"
   ],
   "id": "d7599e2aea388f7b",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T03:33:14.120113Z",
     "start_time": "2024-07-11T03:28:40.367705Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 加载数据集\n",
    "gene_expression = load_csv('EB++AdjustPANCAN_IlluminaHiSeq_RNASeqV2.geneExp.xena', nrows=700)\n",
    "print(\"Size of gene_expression dataset: \", gene_expression.shape)\n",
    "dna_methylation = load_csv('DNA_methylation_450k', nrows=700)\n",
    "print(\"Size of dna_methylation dataset: \", dna_methylation.shape)\n",
    "mirna_expression = load_csv('pancanMiRs_EBadjOnProtocolPlatformWithoutRepsWithUnCorrectMiRs_08_04_16.xena', nrows=700)\n",
    "print(\"Size of mirna_expression dataset: \", mirna_expression.shape)\n",
    "# clinical_data = pd.read_csv('Survival_SupplementalTable_S1_20171025_xena_sp', error_bad_lines=False)\n",
    "# print(\"clinical_data loaded\")"
   ],
   "id": "5e861031e841e170",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T03:33:52.793502Z",
     "start_time": "2024-07-11T03:33:18.973639Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 获取每个数据集的列名（样本 ID）\n",
    "gene_expression_samples = set(gene_expression.columns)\n",
    "dna_methylation_samples = set(dna_methylation.columns)\n",
    "miRNA_expression_samples = set(mirna_expression.columns)\n",
    "\n",
    "# 找到所有数据集中共有的样本 ID\n",
    "common_samples = gene_expression_samples & dna_methylation_samples & miRNA_expression_samples\n",
    "\n",
    "common_samples = list(common_samples)\n",
    "\n",
    "# 使用共有的样本 ID 来过滤每个数据集\n",
    "gene_expression_data = gene_expression[common_samples]\n",
    "dna_methylation_data = dna_methylation[common_samples]\n",
    "miRNA_expression_data = mirna_expression[common_samples]\n",
    "print(\"Size of gene_expression_data: \", gene_expression_data.shape)\n",
    "print(\"Size of dna_methylation_data: \", dna_methylation_data.shape)\n",
    "print(\"Size of miRNA_expression_data: \", miRNA_expression_data.shape)\n",
    "\n",
    "print(\"load dataset Successfully\")\n",
    "\n",
    "# 定义清理函数\n",
    "def clean_data(data):\n",
    "    data = data.apply(pd.to_numeric, errors='coerce')\n",
    "    data = data.dropna(axis=1, thresh=0.7*data.shape[0])\n",
    "    data = data.apply(lambda row: row.fillna(row.mean()), axis=1)\n",
    "    data = data.fillna(0)\n",
    "    return data"
   ],
   "id": "c3565f912e3a0377",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 清理每种数据\n",
    "gene_expression_data = clean_data(gene_expression_data)\n",
    "dna_methylation_data = clean_data(dna_methylation_data)\n",
    "mirna_expression_data = clean_data(miRNA_expression_data)\n",
    "# 数据预处理\n",
    "# 只使用数值列进行标准化\n",
    "gene_expression_data = gene_expression_data.iloc[1:, 1:].values.T\n",
    "dna_methylation_data = dna_methylation_data.iloc[1:, 1:].values.T\n",
    "mirna_expression_data = mirna_expression_data.iloc[1:, 1:].values.T\n",
    "\n",
    "print(\"Size of gene_expression_data: \", gene_expression_data.shape)\n",
    "print(\"Size of dna_methylation_data: \", dna_methylation_data.shape)\n",
    "print(\"Size of miRNA_expression_data: \", mirna_expression_data.shape)\n",
    "\n",
    "# Replace NaN values with the mean of the column\n",
    "gene_expression_data = np.nan_to_num(gene_expression_data, nan=np.nanmean(gene_expression_data))\n",
    "dna_methylation_data = np.nan_to_num(dna_methylation_data, nan=np.nanmean(dna_methylation_data))\n",
    "mirna_expression_data = np.nan_to_num(mirna_expression_data, nan=np.nanmean(mirna_expression_data))"
   ],
   "id": "f9209d09f6e7b073"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T03:34:30.965826Z",
     "start_time": "2024-07-11T03:33:56.774404Z"
    }
   },
   "cell_type": "code",
   "source": [
    "scaler = StandardScaler()\n",
    "gene_expression_scaled = scaler.fit_transform(gene_expression_data)\n",
    "dna_methylation_scaled = scaler.fit_transform(dna_methylation_data)\n",
    "mirna_expression_scaled = scaler.fit_transform(mirna_expression_data)\n",
    "\n",
    "# PCA降维\n",
    "pca_gene = PCA(n_components=50)\n",
    "pca_dna = PCA(n_components=50)\n",
    "pca_mirna = PCA(n_components=50)\n",
    "\n",
    "print(\"PCA step completed\")\n",
    "\n",
    "gene_expression_pca = pca_gene.fit_transform(gene_expression_scaled)\n",
    "dna_methylation_pca = pca_dna.fit_transform(dna_methylation_scaled)\n",
    "mirna_expression_pca = pca_mirna.fit_transform(mirna_expression_scaled)\n",
    "\n",
    "# 数据整合\n",
    "integrated_data = np.concatenate([gene_expression_pca, dna_methylation_pca, mirna_expression_pca], axis=1)\n",
    "print(\"Size of integrated_data: \", integrated_data.shape)\n",
    "\n",
    "# 转换为张量\n",
    "X_integrated = torch.tensor(integrated_data, dtype=torch.float32)\n",
    "y_dummy = torch.tensor(np.random.randint(0, 5, integrated_data.shape[0]), dtype=torch.long)\n",
    "\n",
    "# 创建数据加载器\n",
    "dataset = TensorDataset(X_integrated,y_dummy)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# 检查是否有可用的GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n"
   ],
   "id": "600d6cd8b3878db6",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 7000 and the array at index 2 has size 700",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 14\u001B[0m\n\u001B[1;32m     11\u001B[0m dna_methylation_pca \u001B[38;5;241m=\u001B[39m pca_dna\u001B[38;5;241m.\u001B[39mfit_transform(dna_methylation_scaled)\n\u001B[1;32m     12\u001B[0m mirna_expression_pca \u001B[38;5;241m=\u001B[39m pca_mirna\u001B[38;5;241m.\u001B[39mfit_transform(mirna_expression_scaled)\n\u001B[0;32m---> 14\u001B[0m integrated_data \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconcatenate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mgene_expression_pca\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdna_methylation_pca\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmirna_expression_pca\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mValueError\u001B[0m: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 7000 and the array at index 2 has size 700"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 定义模型\n",
    "class MultiOmicsNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiOmicsNN, self).__init__()\n",
    "        self.fc_gene = nn.Sequential(\n",
    "            nn.Linear(50, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc_dna = nn.Sequential(\n",
    "            nn.Linear(50, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc_mirna = nn.Sequential(\n",
    "            nn.Linear(50, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc_combined = nn.Sequential(\n",
    "            nn.Linear(16 * 3, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 150)\n",
    "        )\n",
    "\n",
    "    def forward(self, x_integrated):\n",
    "        x_gene_encoded = self.fc_gene(x_integrated[:, :50])\n",
    "        x_dna_encoded = self.fc_dna(x_integrated[:, 50:100])\n",
    "        x_mirna_encoded = self.fc_mirna(x_integrated[:, 100:])\n",
    "        x_combined = torch.cat((x_gene_encoded, x_dna_encoded, x_mirna_encoded), dim=1)\n",
    "        output = self.fc_combined(x_combined)\n",
    "        return output\n",
    "\n",
    "model = MultiOmicsNN().to(device)\n",
    "\n",
    "# 定义优化器和损失函数\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "# 定义重构损失函数\n",
    "def reconstruction_loss(reconstructed, original):\n",
    "    mse_loss = nn.MSELoss()\n",
    "    return mse_loss(reconstructed, original)"
   ],
   "id": "79d9c26ab3602dd5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 训练模型\n",
    "num_epochs = 50\n",
    "prev_loss = float('inf')\n",
    "loss_list = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    for X,_ in dataloader:\n",
    "\n",
    "        X = X.to(device)\n",
    "\n",
    "        # 前向传播\n",
    "        outputs= model(X)\n",
    "        loss = reconstruction_loss(outputs, X)\n",
    "\n",
    "        # 反向传播和优化\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    epoch_loss /= len(dataloader)\n",
    "    loss_list.append(epoch_loss)\n",
    "\n",
    "\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss:.4f}')"
   ],
   "id": "b3b1c6febad43555"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 在整个数据集上重新计算模型的输出\n",
    "all_outputs = []\n",
    "model.eval()  # 切换到评估模式\n",
    "with torch.no_grad():\n",
    "    for X, _ in dataloader:\n",
    "        X = X.to(device)\n",
    "        output_batch = model(X)\n",
    "        all_outputs.append(output_batch.cpu().numpy())\n",
    "\n",
    "# 合并所有批次的输出\n",
    "all_outputs = np.concatenate(all_outputs, axis=0)\n",
    "print(\"Size of all_outputs: \", all_outputs.shape)\n",
    "\n",
    "# 使用聚类算法进行聚类分析\n",
    "kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "labels = kmeans.fit_predict(all_outputs)\n",
    "\n",
    "# 结果评估（轮廓系数）\n",
    "silhouette_avg = silhouette_score(all_outputs, labels)\n",
    "print(f'Silhouette Score: {silhouette_avg}')"
   ],
   "id": "489a0ff0d35df50f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 使用PCA降维\n",
    "pca = PCA(n_components=2)\n",
    "outputs_2d = pca.fit_transform(all_outputs)\n",
    "\n",
    "# 绘制散点图\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(outputs_2d[:, 0], outputs_2d[:, 1], c=labels)\n",
    "plt.title('Cluster Visualization')\n",
    "plt.savefig('cluster_visualization.png')  # 保存图像而不是显示\n",
    "\n",
    "\n",
    "# 绘制训练的损失曲线\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(loss_list, label='Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig('training_loss.png')  # 保存图像而不是显示"
   ],
   "id": "22842fe6fca73086"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 生存分析\n",
    "# clinical_data['cluster'] = labels\n",
    "#\n",
    "# kmf = KaplanMeierFitter()\n",
    "# for cluster in clinical_data['cluster'].unique():\n",
    "#     cluster_data = clinical_data[clinical_data['cluster'] == cluster]\n",
    "#     kmf.fit(cluster_data['Overall_Survival_(months)'], event_observed=cluster_data['Overall_Survival_Status'])\n",
    "#     kmf.plot_survival_function(label=f'Cluster {cluster}')\n"
   ],
   "id": "ba8b1e62b725fded"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
